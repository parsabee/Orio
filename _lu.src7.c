__global__ void orcu_kernel9592(const int n, const int m, double* A) {
  const int tid=blockIdx.x*blockDim.x+threadIdx.x;
  const int gsize=gridDim.x*blockDim.x;
  int j, i;
  for (int k=tid; k<=n-1; k+=gsize) {
    {
      for (j=k+1; j<=m-1; j++ ) 
        A[k*N+j]=A[k*N+j]/A[k*N+k];
      for (i=k+1; i<=m-1; i++ ) 
        for (j=k+1; j<=m-1; j++ ) 
          A[i*N+j]=A[i*N+j]-A[i*N+k]*A[k*N+j];
    }
  }
}
void LU(double* A, double* L, double* U, int n) {

/*@ begin PerfTuning (
    def performance_params {
        param thread_count[]  = [32, 64];
        param block_count[]  = range(14,28,14);
        param inner_loop_unroll_fact[] = range(1, 5);
        param preferred_L1_cache[]  = [16, 48];
        param stream_count[] = [2];
        param CFLAGS[] = ['-O3'];
    }

    def input_params
    {
      param N = 500;
    }

    def input_vars
    {
        decl static double L[N * N] = random;
        decl static double U[N * N] = random;
        decl static double A[N * N] = random;

    }

    def search
    {
        arg algorithm = 'Randomlocal';
        arg total_runs = 1000;
    }

    def build {
      arg build_command = 'nvcc -arch=sm_75 @CFLAGS';
    }

    def performance_counter {
      arg method = 'basic timer';
      arg repetitions = 1;
    }
) @*/
/**-- (Generated by Orio) 
Best performance cost: 
  [63.0313] 
Tuned for specific problem sizes: 
  N = 500 
Best performance parameters: 
  CFLAGS = -O3 
  block_count = 14 
  inner_loop_unroll_fact = 4 
  preferred_L1_cache = 48 
  stream_count = 2 
  thread_count = 64 
--**/


int n = N;
int m = N;

#define max(x,y)    ((x) > (y)? (x) : (y))
#define min(x,y)    ((x) < (y)? (x) : (y))

/*@ begin Loop(
  transform CUDA(threadCount=thread_count,
                 blockCount=block_count,
                 preferL1Size=preferred_L1_cache,
                 unrollInner=inner_loop_unroll_fact,
                 streamCount=stream_count)
    for (k=0; k<=n-1; k++) {
      for (j=k+1; j<=m-1; j++)
        A[k * N + j] = A[k * N + j]/A[k * N + k];

      for(i=k+1; i<=m-1; i++)
        for (j=k+1; j<=m-1; j++)
          A[i * N + j] = A[i * N +j] - A[i * N + k]*A[k * N + j];
    }
) @*/
{
  cudaDeviceSynchronize();
  /*declare variables*/
  double* dev_A;
  int nthreads=64;
  int nstreams=2;
  /*calculate device dimensions with the cuda calculator*/
  dim3 dimGrid, dimBlock;
  dimBlock.x=nthreads;
  dimGrid.x=14;
  /*create streams*/
  int istream, soffset;
  cudaStream_t stream[nstreams+1];
  for (istream=0; istream<=nstreams; istream++ ) 
    cudaStreamCreate(&stream[istream]);
  int chunklen=n/nstreams;
  int chunkrem=n%nstreams;
  /*allocate device memory*/
  cudaMalloc(&dev_A,N *N*sizeof(double));
  cudaHostRegister(A,N *N*sizeof(double),cudaHostRegisterPortable);
  cudaDeviceSetCacheConfig(cudaFuncCachePreferL1);
  /*copy data from host to device*/
  cudaEventRecord(tstart,0);
  for (istream=0; istream<nstreams; istream++ ) {
    soffset=istream*chunklen;
    cudaMemcpyAsync(dev_A+soffset,A+soffset,chunklen*sizeof(double),cudaMemcpyHostToDevice,stream[istream]);
  }
  if (chunkrem!=0) {
    soffset=istream*chunklen;
    cudaMemcpyAsync(dev_A+soffset,A+soffset,chunkrem*sizeof(double),cudaMemcpyHostToDevice,stream[istream]);
  }
  cudaEventRecord(tstop,0);
  cudaEventSynchronize(tstop);
  cudaEventElapsedTime(&orcu_transfer,tstart,tstop);
  cudaEventRecord(start,0);
  /*invoke device kernel*/
  int blks4chunk=dimGrid.x/nstreams;
  if (dimGrid.x%nstreams!=0) 
    blks4chunk++ ;
  for (istream=0; istream<nstreams; istream++ ) {
    soffset=istream*chunklen;
    orcu_kernel9592<<<blks4chunk,dimBlock,0,stream[istream]>>>(chunklen,m,dev_A+soffset);
  }
  if (chunkrem!=0) {
    soffset=istream*chunklen;
    orcu_kernel9592<<<blks4chunk,dimBlock,0,stream[istream]>>>(chunkrem,m,dev_A+soffset);
  }
  cudaEventRecord(stop,0);
  cudaEventSynchronize(stop);
  cudaEventElapsedTime(&orcu_elapsed,start,stop);
  /*copy data from device to host*/
  for (istream=0; istream<nstreams; istream++ ) {
    soffset=istream*chunklen;
    cudaMemcpyAsync(A+soffset,dev_A+soffset,chunklen*sizeof(double),cudaMemcpyDeviceToHost,stream[istream]);
  }
  if (chunkrem!=0) {
    soffset=istream*chunklen;
    cudaMemcpyAsync(A+soffset,dev_A+soffset,chunkrem*sizeof(double),cudaMemcpyDeviceToHost,stream[istream]);
  }
  for (istream=0; istream<=nstreams; istream++ ) 
    cudaStreamSynchronize(stream[istream]);
  cudaDeviceSetCacheConfig(cudaFuncCachePreferNone);
  for (istream=0; istream<=nstreams; istream++ ) 
    cudaStreamDestroy(stream[istream]);
  /*free allocated memory*/
  cudaFree(dev_A);
  cudaHostUnregister(A);
  cudaError_t err=cudaGetLastError();
  if (cudaSuccess!=err) 
    printf("CUDA runtime error: %s@",cudaGetErrorString(err));
}
/*@ end @*/
/*@ end @*/


}



