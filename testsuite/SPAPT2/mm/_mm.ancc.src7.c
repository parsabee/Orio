__global__ void orcu_kernel6902(const int m, const int n, int p, double* A, double* B, double* C) {
  const int tid=blockIdx.x*blockDim.x+threadIdx.x;
  const int gsize=gridDim.x*blockDim.x;
  int j, k;
  for (int i=tid; i<=m-1; i+=gsize) {
    for (j=0; j<=n-1; j++ ) {
      for (k=0; k<=p-1; k++ ) {
        C[i*n+j]=C[i*n+j]+A[i*p+k]*B[k*n+j];
      }
    }
  }
}
void MatMatMult(double* A, double* B, double* C, int m, int n, int p) {

/*@ begin PerfTuning (
    def performance_params {
        param thread_count[]  = [32, 64];
        param block_count[]  = range(14,28,14);
        param inner_loop_unroll_fact[] = range(1, 5);
        param preferred_L1_cache[]  = [16, 48];
        param stream_count[] = [1];
        param CFLAGS[] = ['-O3'];
    }

    def input_params
    {
        param CONT = 500;
        param NCONT = 500;
        param M = 500;
        param N = 500;
        param K = 500;
    }

    def input_vars
    {
        decl static double A[M][K] = random;
        decl static double B[K][N] = random;
        decl static double C[M][N] = 0;
    }

    def search
    {
        arg algorithm = 'Randomlocal';
        arg total_runs = 1000;
    }

    def build {
      arg build_command = 'nvcc -arch=sm_75 @CFLAGS';
    }

    def performance_counter {
      arg method = 'basic timer';
      arg repetitions = 1;
    }
) @*/
/**-- (Generated by Orio) 
Best performance cost: 
  [194.65] 
Tuned for specific problem sizes: 
  CONT = 500 
  K = 500 
  M = 500 
  N = 500 
  NCONT = 500 
Best performance parameters: 
  CFLAGS = -O3 
  block_count = 14 
  inner_loop_unroll_fact = 1 
  preferred_L1_cache = 48 
  stream_count = 1 
  thread_count = 32 
--**/


int m = M, p = K, n = N;

#define max(x,y)    ((x) > (y)? (x) : (y))
#define min(x,y)    ((x) < (y)? (x) : (y))

/*@ begin Loop(
  transform CUDA(threadCount=thread_count,
                 blockCount=block_count,
                 preferL1Size=preferred_L1_cache,
                 unrollInner=inner_loop_unroll_fact,
                 streamCount=stream_count)
  for(i=0; i<=m-1; i++)
    for(j=0; j<=n-1; j++) {
      for(k=0; k<=p-1; k++){
        C[i*n+j] += A[i*p+k]*B[k*n+j];
      }
    }
) @*/
{
  cudaDeviceSynchronize();
  /*declare variables*/
  double* dev_A;
  double* dev_B;
  double* dev_C;
  int nthreads=32;
  /*calculate device dimensions with the cuda calculator*/
  dim3 dimGrid, dimBlock;
  int __tmpMinGridSize, __tmpBlockSize;
  cudaOccupancyMaxPotentialBlockSize(&__tmpMinGridSize,&__tmpBlockSize,orcu_kernel6902);
  dimGrid.x=(m+__tmpBlockSize-1)/__tmpBlockSize;
  dimBlock.x=__tmpBlockSize;
  /*allocate device memory*/
  cudaMalloc(&dev_B,K*sizeof(double));
  cudaMalloc(&dev_C,M*sizeof(double));
  cudaMalloc(&dev_A,M*sizeof(double));
  cudaDeviceSetCacheConfig(cudaFuncCachePreferL1);
  /*copy data from host to device*/
  cudaEventRecord(tstart,0);
  cudaMemcpy(dev_B,B,K*sizeof(double),cudaMemcpyHostToDevice);
  cudaMemcpy(dev_C,C,M*sizeof(double),cudaMemcpyHostToDevice);
  cudaMemcpy(dev_A,A,M*sizeof(double),cudaMemcpyHostToDevice);
  cudaEventRecord(tstop,0);
  cudaEventSynchronize(tstop);
  cudaEventElapsedTime(&orcu_transfer,tstart,tstop);
  cudaEventRecord(start,0);
  /*invoke device kernel*/
  orcu_kernel6902<<<dimGrid,dimBlock>>>(m,n,p,dev_A,dev_B,dev_C);
  cudaEventRecord(stop,0);
  cudaEventSynchronize(stop);
  cudaEventElapsedTime(&orcu_elapsed,start,stop);
  /*copy data from device to host*/
  cudaMemcpy(C,dev_C,M*sizeof(double),cudaMemcpyDeviceToHost);
  cudaDeviceSetCacheConfig(cudaFuncCachePreferNone);
  /*free allocated memory*/
  cudaFree(dev_A);
  cudaFree(dev_B);
  cudaFree(dev_C);
  cudaError_t err=cudaGetLastError();
  if (cudaSuccess!=err) 
    printf("CUDA runtime error: %s@",cudaGetErrorString(err));
}
/*@ end @*/
/*@ end @*/


}



