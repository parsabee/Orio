__global__ void orcu_kernel1055(const int m, const int p, int n, double* A, double* B, double* C) {
  const int tid=blockIdx.x*blockDim.x+threadIdx.x;
  const int gsize=gridDim.x*blockDim.x;
  double s;
  int j, k;
  for (int i=tid; i<=m-1; i+=gsize) {
    for (j=0; j<=p-1; j++ ) {
      s=0.0;
      for (k=0; k<=n-1; k++ ) {
        s=s+A[i*n+k]*B[k*p+j];
      }
      C[i*n+j]=s;
    }
  }
}
void MatMatMult(double* A, double* B, double* C, int m, int n, int p) {
  register int i,j,k;
  /*@ begin PerfTuning (
        def performance_params {
          param TC[]  = [32];
          param BC[]  = [14];
          param UIF[] = range(1,3);
          param PL[]  = [16];
          param SC[] = [2];
          param CFLAGS[] = ['-O3'];
        }
        def input_params {
          param M[] = [32];
          param N[] = [32];
          param P[] = [32];
        }
        def input_vars {
          decl static double A[M*N] = random;
          decl static double B[N*P] = random;
          decl static double C[M*P] = 0;
        }
        def build {
          arg build_command = 'nvcc -arch=sm_75 @CFLAGS';
        }
        def performance_counter {
          arg method = 'basic timer';
          arg repetitions = 1;
        }
  ) @*/
/**-- (Generated by Orio) 
Best performance cost: 
  [0.07248] 
Tuned for specific problem sizes: 
  M = 32 
  N = 32 
  P = 32 
Best performance parameters: 
  BC = 14 
  CFLAGS = -O3 
  PL = 16 
  SC = 2 
  TC = 32 
  UIF = 1 
--**/


  int m = M, p = P, n = N;
  /*@ begin Loop(transform CUDA(threadCount=TC, blockCount=BC, preferL1Size=PL, unrollInner=UIF)

  for(i=0; i<=m-1; i++){
    for(j=0; j<=p-1; j++){
      s = 0.0;
      for(k=0; k<=n-1; k++){
        s += A[i*n+k]*B[k*p+j];
      }
      C[i*n+j]=s;
    }
  }
  ) @*/
  {
    cudaDeviceSynchronize();
    /*declare variables*/
    double* dev_A;
    double* dev_B;
    double* dev_C;
    int nthreads=32;
    /*calculate device dimensions*/
    dim3 dimGrid, dimBlock;
    dimBlock.x=nthreads;
    dimGrid.x=14;
    /*allocate device memory*/
    cudaMalloc(&dev_C,M *P*sizeof(double));
    cudaMalloc(&dev_B,N *P*sizeof(double));
    cudaMalloc(&dev_A,M *N*sizeof(double));
    cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
    /*copy data from host to device*/
    cudaEventRecord(tstart,0);
    cudaMemcpy(dev_B,B,N *P*sizeof(double),cudaMemcpyHostToDevice);
    cudaMemcpy(dev_A,A,M *N*sizeof(double),cudaMemcpyHostToDevice);
    cudaEventRecord(tstop,0);
    cudaEventSynchronize(tstop);
    cudaEventElapsedTime(&orcu_transfer,tstart,tstop);
    cudaEventRecord(start,0);
    /*invoke device kernel*/
    orcu_kernel1055<<<dimGrid,dimBlock>>>(m,p,n,dev_A,dev_B,dev_C);
    cudaEventRecord(stop,0);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&orcu_elapsed,start,stop);
    /*copy data from device to host*/
    cudaMemcpy(C,dev_C,M *P*sizeof(double),cudaMemcpyDeviceToHost);
    cudaDeviceSetCacheConfig(cudaFuncCachePreferNone);
    /*free allocated memory*/
    cudaFree(dev_A);
    cudaFree(dev_B);
    cudaFree(dev_C);
    cudaError_t err=cudaGetLastError();
    if (cudaSuccess!=err) 
      printf("CUDA runtime error: %s@",cudaGetErrorString(err));
  }
  /*@ end @*/
    /*@ end @*/
}
